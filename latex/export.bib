@article{axioms,
author = {Worden, Keith and Farrar, Charles and Manson, Graeme},
year = {2007},
month = {06},
pages = {1639-1664},
title = {The Fundamental Axioms of Structural Health Monitoring},
volume = {463},
journal = {Proceedings of The Royal Society A: Mathematical, Physical and Engineering Sciences},
doi = {10.1098/rspa.2007.1834}
}

@article{report_dataset,
title = {Structural health monitoring algorithm comparisons using standard data sets},
author = {Figueiredo, Eloi and Park, Gyuhae and Figueiras, Joaquim and Farrar, Charles and Worden, Keith},
abstractNote = {The real-world structures are subjected to operational and environmental condition changes that impose difficulties in detecting and identifying structural damage. The aim of this report is to detect damage with the presence of such operational and environmental condition changes through the application of the Los Alamos National Laboratoryís statistical pattern recognition paradigm for structural health monitoring (SHM). The test structure is a laboratory three-story building, and the damage is simulated through nonlinear effects introduced by a bumper mechanism that simulates a repetitive impact-type nonlinearity. The report reviews and illustrates various statistical principles that have had wide application in many engineering fields. The intent is to provide the reader with an introduction to feature extraction and statistical modelling for feature classification in the context of SHM. In this process, the strengths and limitations of some actual statistical techniques used to detect damage in the structures are discussed. In the hierarchical structure of damage detection, this report is only concerned with the first step of the damage detection strategy, which is the evaluation of the existence of damage in the structure. The data from this study and a detailed description of the test structure are available for download at: http://institute.lanl.gov/ei/software-and-data/.},
doi = {10.2172/961604},
url = {https://www.osti.gov/biblio/961604},
journal = {},
place = {United States},
year = {2009},
month = {3}
}

@article{autoreg,
author = {Figueiredo, Eloi and Figueiras, Joaquim and Park, Gyuhae and Farrar, Charles R. and Worden, Keith},
title = {Influence of the Autoregressive Model Order on Damage Detection},
journal = {Computer-Aided Civil and Infrastructure Engineering},
volume = {26},
number = {3},
pages = {225-238},
doi = {https://doi.org/10.1111/j.1467-8667.2010.00685.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8667.2010.00685.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8667.2010.00685.x},
abstract = {Abstract:? An important step for using time-series autoregressive (AR) models for structural health monitoring is the estimation of the appropriate model order. To obtain an optimal AR model order for such processes, this article presents and discusses four techniques based on Akaike information criterion, partial autocorrelation function, root mean squared error, and singular value decomposition. A unique contribution of this work is to provide a comparative study with three different AR models that is carried out to understand the influence of the model order on the damage detection process in the presence of simulated operational and environmental variability. A three-story base-excited frame structure was used as a test bed in a laboratory setting, and data sets were measured for several structural state conditions. Damage was introduced by a bumper mechanism that induces a repetitive impact-type nonlinearity. The operational and environmental effects were simulated by adding mass and by changing the stiffness properties of the columns. It was found that these four techniques do not converge to a unique solution, rather all require somewhat qualitative interpretation to define the optimal model order. The comparative study carried out on these data sets shows that the AR model order range defined by the four techniques provides robust damage detection in the presence of simulated operational and environmental variability.},
year = {2011}
}

@Inbook{pca,
author="Jolliffe, Ian",
title="Principal Component Analysis",
bookTitle="International Encyclopedia of Statistical Science",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1094--1096",
isbn="978-3-642-04898-2",
doi="10.1007/978-3-642-04898-2_455",
url="https://doi.org/10.1007/978-3-642-04898-2_455"
}

@article{pca_original,
  title={Analysis of a complex of statistical variables into principal components.},
  author={Harold Hotelling},
  journal={Journal of Educational Psychology},
  year={1933},
  volume={24},
  pages={498-520}
}

@book{HECHTNIELSEN199265,
title = {III.3 - Theory of the Backpropagation Neural Network**Based on ‚Äúnonindent‚Äù by Robert Hecht-Nielsen, which appeared in Proceedings of the International Joint Conference on Neural Networks 1, 593‚Äì611, June 1989. ¬© 1989 IEEE.},
booktitle = {Neural Networks for Perception},
publisher = {Academic Press},
pages = {65-93},
year = {1992},
isbn = {978-0-12-741252-8},
doi = {https://doi.org/10.1016/B978-0-12-741252-8.50010-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780127412528500108},
author = {Robert Hetch-Nielsen},
abstract = {Publisher Summary
This chapter presents a survey of the elementary theory of the basic backpropagation neural network architecture, covering the areas of architectural design, performance measurement, function approximation capability, and learning. The survey includes a formulation of the backpropagation neural network architecture to make it a valid neural network and a proof that the backpropagation mean squared error function exists and is differentiable. Also included in the survey is a theorem showing that any L2 function can be implemented to any desired degree of accuracy with a three-layer backpropagation neural network. An appendix presents a speculative neurophysiological model illustrating the way in which the backpropagation neural network architecture might plausibly be implemented in the mammalian brain for corticocortical learning between nearby regions of cerebral cortex. One of the crucial decisions in the design of the backpropagation architecture is the selection of a sigmoidal activation function.}
}

@book{haykin99a,
  added-at = {2014-04-01T19:25:15.000+0200},
  author = {Haykin, Simon},
  biburl = {https://www.bibsonomy.org/bibtex/2e13a49ec715f4e52f1dcca0d4c5c8b2c/prlz77},
  description = {Thesis BIB},
  interhash = {9c833e39d6ac9c0a31aca034fb641190},
  intrahash = {e13a49ec715f4e52f1dcca0d4c5c8b2c},
  keywords = {A Comprehensive Foundation Networks: Neural},
  publisher = {Prentice Hall},
  timestamp = {2014-04-01T19:25:15.000+0200},
  title = {Neural Networks: A Comprehensive Foundation},
  year = 1999
}

@book{haykin2,
  added-at = {2014-04-01T19:25:15.000+0200},
  author = {Haykin, Simon},
  description = {Thesis BIB},
  keywords = {Neural Networks and Learning Machines},
  publisher = {Prentice Hall},
  timestamp = {2014-04-01T19:25:15.000+0200},
  title = {Neural Networks and Learning Machines},
  year = 1999
}

@book{geron2017hands-on,
  added-at = {2018-04-06T05:58:31.000+0200},
  address = {Sebastopol, CA},
  author = {Geron, Aurelien},
  biburl = {https://www.bibsonomy.org/bibtex/2a91270a3a516f4edaa5d459c40317fcc/achakraborty},
  interhash = {e2bd4a803c6cba6cca1d926b393806ad},
  intrahash = {a91270a3a516f4edaa5d459c40317fcc},
  isbn = {978-1491962299},
  keywords = {2017 book machine-learning oreilly tensorflow textbook},
  publisher = {O'Reilly Media},
  timestamp = {2018-04-06T05:59:31.000+0200},
  title = {Hands-on machine learning with Scikit-Learn and TensorFlow : concepts, tools, and techniques to build intelligent systems},
  year = 2017
}

@book{kohonen,
  added-at = {2010-06-28T21:14:25.000+0200},
  address = {Berlin},
  author = {Kohonen, Teuvo},
  biburl = {https://www.bibsonomy.org/bibtex/288cd8358c519cf9615363b69d91db66e/mhwombat},
  citeulike-article-id = {190492},
  citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&path=ASIN/3540679219},
  citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&path=ASIN/3540679219},
  citeulike-linkout-10 = {http://www.worldcat.org/oclc/45284682},
  citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&path=ASIN/3540679219},
  citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/3540679219},
  citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/3540679219/citeulike00-21},
  citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/3540679219},
  citeulike-linkout-6 = {http://www.worldcat.org/isbn/3540679219},
  citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN3540679219},
  citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=3540679219\&index=books\&linkCode=qs},
  citeulike-linkout-9 = {http://www.librarything.com/isbn/3540679219},
  day = 28,
  edition = {3rd},
  groups = {public},
  howpublished = {Paperback},
  interhash = {ccad3f96b0b87d57743319ef020caec9},
  intrahash = {88cd8358c519cf9615363b69d91db66e},
  isbn = {978-3-540-67921-9},
  keywords = {kohonen som},
  month = dec,
  posted-at = {2010-06-26 08:29:47},
  priority = {2},
  publisher = {Springer},
  series = {Springer series in information sciences, 30},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {Self-organizing maps},
  url = {http://www.worldcat.org/isbn/3540679219},
  username = {mhwombat},
  year = 2001
}
